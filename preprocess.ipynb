{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f32b949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install soynlp -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3cc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "def preprocessing(text):\n",
    "    # 문제를 일으킬 수 있는 문자 제거\n",
    "    bad_chars = {\"\\u200b\": \"\", \"…\": \" ... \", \"\\ufeff\": \"\"}\n",
    "    for bad_char in bad_chars:\n",
    "        text = text.replace(bad_char, bad_chars[bad_char])\n",
    "        \n",
    "    error_chars = {\"\\u3000\": \" \", \"\\u2009\": \" \", \"\\u2002\": \" \", \"\\xa0\":\" \"}\n",
    "    for error_char in error_chars:\n",
    "        text = text.replace(error_char, error_chars[error_char])\n",
    "    \n",
    "    # 이메일 제거\n",
    "    text = re.sub(r\"[a-zA-Z0-9+-_.]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", \" \", text).strip()\n",
    "    \n",
    "    # \"#문자\" 형식 어절 제거\n",
    "    text = re.sub(r\"#\\S+\", \"\", text).strip()\n",
    "    \n",
    "    # \"@문자\" 형식 어절 제거\n",
    "    text = re.sub(r\"@\\w+\", \"\", text).strip()\n",
    "    \n",
    "    # URL 제거\n",
    "    text = re.sub(r\"(http|https)?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \" \", text).strip()\n",
    "    text = re.sub(r\"pic\\.(\\w+\\.)+\\S*\", \" \", text).strip()\n",
    "    \n",
    "    # 뉴스 저작권 관련 텍스트 제거\n",
    "    re_patterns = [\n",
    "        r\"\\<저작권자(\\(c\\)|ⓒ|©|\\(Copyright\\)|(\\(c\\))|(\\(C\\))).+?\\>\",\n",
    "        r\"저작권자\\(c\\)|ⓒ|©|(Copyright)|(\\(c\\))|(\\(C\\))\"\n",
    "    ]\n",
    "    \n",
    "    for re_pattern in re_patterns:\n",
    "        text = re.sub(re_pattern, \"\", text).strip()\n",
    "    \n",
    "    # 뉴스 내 포함된 이미지에 대한 레이블 제거\n",
    "    text = re.sub(r\"\\(출처 ?= ?.+\\) |\\(사진 ?= ?.+\\) |\\(자료 ?= ?.+\\)| \\(자료사진\\) |사진=.+기자 \", \"\", text).strip()\n",
    "    \n",
    "    # 중복 문자 처리\n",
    "    text = repeat_normalize(text, num_repeats=2).strip()\n",
    "    \n",
    "    # 문제를 일으킬 수 있는 구두점 치환\n",
    "    punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n",
    "    for p in punct_mapping:\n",
    "        text = text.replace(p, punct_mapping[p])\n",
    "    \n",
    "    # 연속된 공백 치환\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    # 개행 문자 \"\\n\" 제거\n",
    "    text = text.replace('\\n', '')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4edbde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# pp_df는 전처리 된 데이터\n",
    "pp_df = pd.DataFrame({'context':[]})\n",
    "\n",
    "keyword = 'episode_2'\n",
    "data_dir = f'/Users/yongchanchun/Desktop/MacBook_Pro_Desktop/해커톤/{keyword}'\n",
    "save_dir = f'/Users/yongchanchun/Desktop/MacBook_Pro_Desktop/해커톤/preprocessed_{keyword}'\n",
    "\n",
    "# 3. 카테고리별로 폴더 생성하는 함수\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "createFolder(save_dir)\n",
    "\n",
    "for text_name in sorted(os.listdir(data_dir)):\n",
    "    text_dir = os.path.join(data_dir, text_name)\n",
    "    with open(text_dir, 'r') as f:\n",
    "        raw_data = f.read()\n",
    "        if raw_data == '':\n",
    "            continue\n",
    "        preprocessed_text = preprocessing(raw_data)\n",
    "        pp_df = pp_df.append({'context': preprocessed_text}, ignore_index=True)\n",
    "   \n",
    "pp_df.head(10)\n",
    "pp_df.to_csv(os.path.join(save_dir, f'{keyword}.txt'), sep='\\t', header=False, index=False)\n",
    "\n",
    "with open(os.path.join(save_dir, f'{keyword}_merged.txt'), 'w') as f:\n",
    "    for i, text in enumerate(pp_df['context']):\n",
    "        if i != 0:\n",
    "            f.write('\\n'+text)\n",
    "        else:\n",
    "            f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (v3.8.5:580fbb018f, Jul 20 2020, 12:11:27) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
